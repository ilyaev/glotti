<p align="center">
  <img src="client/public/glotti_logo.png" alt="Glotti Logo" width="200" />
</p>

<p align="center">
  <strong>Real-time AI sparring partner for high-stakes verbal interactions</strong>
</p>

<p align="center">
  <a href="#scenario-modes">Modes</a> â€¢
  <a href="#architecture">Architecture</a> â€¢
  <a href="#getting-started">Getting Started</a> â€¢
  <a href="#deployment">Deployment</a> â€¢
  <a href="https://glotti.pbartz.net/">Try It Live</a>
</p>

---

## The Idea

Glotti is a real-time AI sparring partner that trains you for pitches, negotiations, debates, and difficult conversations. Unlike passive post-hoc feedback tools, Glotti **interrupts you mid-sentence** with challenges, corrections, and tactical cues â€” forcing you to adapt under pressure exactly as you would in a real encounter.

The core innovation is leveraging **Gemini Live API's bidirectional audio streaming** to create a sparring partner that *listens* to you in real-time, delivering feedback at the speed of conversation.

### What Makes Glotti Different

- **Real-time interruption** â€” The agent challenges you *while* you speak, training genuine composure under pressure. Not post-hoc.
- **Configurable personas** â€” Each scenario mode has its own personality, escalation logic, and evaluation rubric.
- **Live metrics dashboard** â€” Filler word count, speaking pace, tone confidence, and talk ratio update in real-time on screen.
- **Post-session reports** â€” Structured breakdowns with timestamps, key moments, scores, and actionable improvement tips.
- **Feedback sessions** â€” After reviewing your report, rejoin a voice session with the same AI persona to discuss your performance, ask questions, and get targeted advice based on what happened in the original session.
- **Social sharing** â€” Auto-generated performance cards with OG image previews for sharing results on LinkedIn, X, and more.

---

## Scenario Modes

Glotti ships with multiple AI personas, each with a unique system prompt, interruption strategy, and evaluation criteria.

### PitchPerfect â€” Startup Founder Sparring
A skeptical venture capitalist who listens to your startup pitch and interrupts with tough investor questions. Tracks filler words, speaking pace, time spent on problem vs. solution, and conviction level.

### EmpathyTrainer â€” Difficult Conversations Trainer
Adopts the emotional stance of an upset counterparty (customer, employee, parent). Detects your tone â€” if you sound defensive or dismissive, the agent escalates. Demonstrate empathy and it de-escalates. Tracks empathy score, defensive language ratio, and resolution time.

### Veritalk â€” Adversarial Debate Sparring
An aggressive debate opponent that uses **Google Search grounding** to pull real-time counter-arguments and fact-checks. Forces you to think on your feet. Tracks argument coherence, recovery time after interruption, and logical fallacy count.

### Impromptu â€” Spontaneous Speaking
Practice building structure on the fly with surprise topics. Evaluated on clarity, structure (open â†’ develop â†’ close), confidence markers, and filler word discipline.

---

## Architecture

### High-Level Overview

```mermaid
graph LR
    Client["Browser Client<br/>React + Vite"] <-->|"WebSocket<br/>audio PCM / JSON"| Backend["Node.js Backend<br/>Express + ws"]
    Backend <-->|"Gemini Live API<br/>audio / transcript"| Gemini["Gemini<br/>2.5 Flash"]

    Backend --- Persona["Persona Agent<br/>(persona-driven conversation)"]
    Backend --- ADK["Google ADK<br/>(report gen, analytics, tone)"]
    Backend --- Firestore["Firestore<br/>(session persistence & reports)"]
    ADK --- Gemini2["Gemini 2.5 Flash<br/>(non-streaming)"]
```

### Key Technical Decisions

| Decision | Rationale |
|---|---|
| **WebSocket proxy pattern** | The backend sits between browser and Gemini Live API â€” pipes audio bidirectionally while simultaneously extracting metrics and managing session state. This enables server-side analytics without adding client latency. |
| **Gemini Live API** | Bidirectional audio streaming with barge-in support. The agent can interrupt the user mid-sentence and the user can interrupt the agent â€” enabling natural, pressure-testing conversation flow. |
| **Google ADK (limited)** | ADK `LlmAgent` + `Runner.runAsync()` for post-session report generation; `InMemoryRunner.runEphemeral()` for real-time tone analysis and analytics. Live audio streaming remains on raw `@google/genai` â€” ADK's `Runner.runLive()` is not yet implemented in the TypeScript SDK. |
| **Google Cloud native** | Cloud Run for containerized hosting (scales to zero), Firestore for session persistence, Secret Manager for API keys. Single `npm run deploy` command. |
| **Persona-as-prompt** | Each scenario is defined by a markdown system prompt in `server/agents/prompts/`. Adding a new mode requires only writing a prompt file and registering it in config â€” no code changes to the core engine. |
| **Server-side OG image generation** | Social share previews use Satori + Resvg to render React components to PNG on the server, ensuring rich link previews on LinkedIn, X, Slack, and Discord. |
| **Multi-stage Docker build** | Production image uses a two-stage Dockerfile â€” build stage compiles TypeScript, runtime stage copies only compiled output and production deps for a minimal container. |

> **ðŸ“ Detailed architecture diagrams** â€” See [docs/diagrams.md](docs/diagrams.md) for 8 Mermaid diagrams covering the system at every level: high-level overview, WebSocket protocol, backend modules, audio pipeline, ADK agents, React components, deployment, and session lifecycle state machine.

### Tech Stack

**Client:**
- React 19 + TypeScript
- Vite (dev server + production build)
- Web Audio API / AudioWorklet (mic capture & playback)
- Native WebSocket API (custom `useWebSocket` hook)
- Lucide React (icons)
- html-to-image (performance card generation)

**Server:**
- Node.js + Express 5 + TypeScript
- `ws` library (raw WebSocket control for binary audio streaming)
- `@google/genai` SDK (Gemini Live API â€” bidirectional audio streaming)
- `@google/adk` SDK (report generation, tone analysis, analytics â€” non-streaming only)
- Zod (runtime validation)
- Satori + Resvg (server-side OG image rendering)

**Google Cloud:**
- **Cloud Run** â€” Containerized backend, scales to zero
- **Firestore** â€” Session persistence, transcripts, reports
- **Secret Manager** â€” API key storage
- **Cloud Build + Artifact Registry** â€” CI/CD pipeline

---

## Getting Started

### Prerequisites
- Node.js 22+
- A [Gemini API key](https://aistudio.google.com/apikey)

### Installation

```bash
# Clone the repository
git clone https://github.com/ilyaev/glotti.git
cd glotti

# Install dependencies
npm install
cd client && npm install && cd ..

# Configure environment
cp .env.example .env
# Add your GEMINI_API_KEY to .env
```

### Development

```bash
# Start both server and client in dev mode
npm run dev
```

This runs:
- **Server** on `http://localhost:8080` (with hot reload via `tsx watch`)
- **Client** on `http://localhost:5173` (with Vite HMR)

### Production Build

```bash
npm run build        # Builds server (tsc) + client (vite)
npm start            # Starts the production server
```

---

## Deployment

Glotti is designed to run on **Google Cloud Run** as a single containerized service. Deployment is fully automated via infrastructure-as-code scripts included in the repository.

### One-Command Deploy

The [`deploy.sh`](deploy.sh) script handles the entire setup â€” enabling GCP APIs, creating Firestore, storing the API key in Secret Manager, and deploying to Cloud Run:

```bash
./deploy.sh                          # Uses current gcloud project
./deploy.sh --project my-project-id  # Specify a project
./deploy.sh --region europe-west1    # Override region
./deploy.sh --service my-service     # Override service name (default: debatepro-backend)
```

### CI/CD Pipeline

The [`cloudbuild.yaml`](cloudbuild.yaml) defines a Cloud Build pipeline that builds the Docker image, pushes it to Artifact Registry, and deploys to Cloud Run. It can be triggered automatically on push or run manually:

```bash
gcloud builds submit --config cloudbuild.yaml .
```

### Infrastructure-as-Code Files

| File | Purpose |
|---|---|
| [`deploy.sh`](deploy.sh) | Full automated deployment script (APIs, Firestore, secrets, Cloud Run) |
| [`cloudbuild.yaml`](cloudbuild.yaml) | Cloud Build CI/CD pipeline definition |
| [`Dockerfile`](Dockerfile) | Multi-stage container build (TypeScript compile â†’ minimal runtime image) |

See [specs/deployment.md](specs/deployment.md) for detailed manual steps and alternative frontend hosting options.

---

## Project Structure

```
â”œâ”€â”€ server/                  # Node.js backend
â”‚   â”œâ”€â”€ main.ts              # Express + WebSocket server entry
â”‚   â”œâ”€â”€ ws-handler.ts        # WebSocket orchestrator (~120 LOC)
â”‚   â”œâ”€â”€ session/             # Modular session logic
â”‚   â”‚   â”œâ”€â”€ state.ts         # Session state factory
â”‚   â”‚   â”œâ”€â”€ gemini-bridge.ts # Gemini Live API connection
â”‚   â”‚   â”œâ”€â”€ protocol.ts      # Client â†” Server message protocol
â”‚   â”‚   â”œâ”€â”€ metrics.ts       # Speech metrics (filler words, WPM)
â”‚   â”‚   â”œâ”€â”€ transcript-buffer.ts
â”‚   â”‚   â”œâ”€â”€ tone-analyzer.ts # Background LLM tone analysis
â”‚   â”‚   â””â”€â”€ constants.ts     # Tunable thresholds
â”‚   â”œâ”€â”€ adk/                 # Google ADK integration (non-streaming)
â”‚   â”‚   â”œâ”€â”€ agents.ts        # LlmAgent definitions (report agent)
â”‚   â”‚   â”œâ”€â”€ runner.ts        # Runner factory + runReportAgent()
â”‚   â”‚   â””â”€â”€ index.ts         # Barrel exports
â”‚   â”œâ”€â”€ agents/prompts/      # Persona system prompts (markdown)
â”‚   â”œâ”€â”€ api/                 # REST endpoints
â”‚   â””â”€â”€ services/            # OG image rendering
â”œâ”€â”€ client/                  # React frontend
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/      # UI components (Dashboard, Session, Report, etc.)
â”‚       â”œâ”€â”€ hooks/           # Custom hooks (useAudio, useWebSocket, useSessionLogic)
â”‚       â””â”€â”€ utils/           # Shared utilities
â”œâ”€â”€ specs/                   # Technical specifications
â”œâ”€â”€ docs/                    # Product documentation
â””â”€â”€ Dockerfile               # Multi-stage production build
```

---

## Adding a New Mode

1. **Write a system prompt** â€” Create a markdown file in `server/agents/prompts/`
2. **Register the mode** â€” Add it to the `MODES` object in `server/config.ts`
3. **Update client types** â€” Add the mode ID to the `Mode` type
4. **Add a UI card** â€” Add the mode entry to `ModeSelect.tsx` with icon and description

No changes to the WebSocket handler or session engine are needed â€” the persona-as-prompt architecture keeps mode additions purely declarative.

Or just ask your AI coding agent:

> Check `specs/persona.md` for instructions and add a new persona which is a ruthless negotiation opponent for salary and contract discussions

---

## License

MIT
